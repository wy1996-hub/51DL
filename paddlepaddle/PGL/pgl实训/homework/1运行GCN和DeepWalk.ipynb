{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# 第一课：图学习初印象习题\n",
    "\n",
    "搭建环境，运行[GCN](https://arxiv.org/abs/1609.02907)和[DeepWalk](https://dl.acm.org/doi/10.1145/2623330.2623732)。\n",
    "\n",
    "## 1. 环境搭建"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://mirror.baidu.com/pypi/simple/\n",
      "Collecting pgl\n",
      "\u001b[?25l  Downloading https://mirror.baidu.com/pypi/packages/e2/84/6aac242f80a794f1169386d73bdc03f2e3467e4fa85b1286979ddf51b1a0/pgl-1.2.1-cp37-cp37m-manylinux1_x86_64.whl (7.9MB)\n",
      "\u001b[K     |████████████████████████████████| 7.9MB 11.6MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting redis-py-cluster (from pgl)\n",
      "\u001b[?25l  Downloading https://mirror.baidu.com/pypi/packages/2b/c5/3236720746fa357e214f2b9fe7e517642329f13094fc7eb339abd93d004f/redis_py_cluster-2.1.0-py2.py3-none-any.whl (41kB)\n",
      "\u001b[K     |████████████████████████████████| 51kB 19.9MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.16.4 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from pgl) (1.16.4)\n",
      "Requirement already satisfied: cython>=0.25.2 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from pgl) (0.29)\n",
      "Requirement already satisfied: visualdl>=2.0.0b; python_version >= \"3\" in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from pgl) (2.0.3)\n",
      "Collecting redis<4.0.0,>=3.0.0 (from redis-py-cluster->pgl)\n",
      "\u001b[?25l  Downloading https://mirror.baidu.com/pypi/packages/a7/7c/24fb0511df653cf1a5d938d8f5d19802a88cef255706fdda242ff97e91b7/redis-3.5.3-py2.py3-none-any.whl (72kB)\n",
      "\u001b[K     |████████████████████████████████| 81kB 20.4MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: flake8>=3.7.9 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from visualdl>=2.0.0b; python_version >= \"3\"->pgl) (3.8.2)\n",
      "Requirement already satisfied: six>=1.14.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from visualdl>=2.0.0b; python_version >= \"3\"->pgl) (1.15.0)\n",
      "Requirement already satisfied: flask>=1.1.1 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from visualdl>=2.0.0b; python_version >= \"3\"->pgl) (1.1.1)\n",
      "Requirement already satisfied: pre-commit in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from visualdl>=2.0.0b; python_version >= \"3\"->pgl) (1.21.0)\n",
      "Requirement already satisfied: protobuf>=3.11.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from visualdl>=2.0.0b; python_version >= \"3\"->pgl) (3.12.2)\n",
      "Requirement already satisfied: Flask-Babel>=1.0.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from visualdl>=2.0.0b; python_version >= \"3\"->pgl) (1.0.0)\n",
      "Requirement already satisfied: requests in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from visualdl>=2.0.0b; python_version >= \"3\"->pgl) (2.22.0)\n",
      "Requirement already satisfied: Pillow>=7.0.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from visualdl>=2.0.0b; python_version >= \"3\"->pgl) (7.1.2)\n",
      "Requirement already satisfied: mccabe<0.7.0,>=0.6.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from flake8>=3.7.9->visualdl>=2.0.0b; python_version >= \"3\"->pgl) (0.6.1)\n",
      "Requirement already satisfied: pyflakes<2.3.0,>=2.2.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from flake8>=3.7.9->visualdl>=2.0.0b; python_version >= \"3\"->pgl) (2.2.0)\n",
      "Requirement already satisfied: pycodestyle<2.7.0,>=2.6.0a1 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from flake8>=3.7.9->visualdl>=2.0.0b; python_version >= \"3\"->pgl) (2.6.0)\n",
      "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from flake8>=3.7.9->visualdl>=2.0.0b; python_version >= \"3\"->pgl) (0.23)\n",
      "Requirement already satisfied: click>=5.1 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from flask>=1.1.1->visualdl>=2.0.0b; python_version >= \"3\"->pgl) (7.0)\n",
      "Requirement already satisfied: itsdangerous>=0.24 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from flask>=1.1.1->visualdl>=2.0.0b; python_version >= \"3\"->pgl) (1.1.0)\n",
      "Requirement already satisfied: Jinja2>=2.10.1 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from flask>=1.1.1->visualdl>=2.0.0b; python_version >= \"3\"->pgl) (2.10.3)\n",
      "Requirement already satisfied: Werkzeug>=0.15 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from flask>=1.1.1->visualdl>=2.0.0b; python_version >= \"3\"->pgl) (0.16.0)\n",
      "Requirement already satisfied: identify>=1.0.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from pre-commit->visualdl>=2.0.0b; python_version >= \"3\"->pgl) (1.4.10)\n",
      "Requirement already satisfied: pyyaml in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from pre-commit->visualdl>=2.0.0b; python_version >= \"3\"->pgl) (5.1.2)\n",
      "Requirement already satisfied: cfgv>=2.0.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from pre-commit->visualdl>=2.0.0b; python_version >= \"3\"->pgl) (2.0.1)\n",
      "Requirement already satisfied: toml in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from pre-commit->visualdl>=2.0.0b; python_version >= \"3\"->pgl) (0.10.0)\n",
      "Requirement already satisfied: nodeenv>=0.11.1 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from pre-commit->visualdl>=2.0.0b; python_version >= \"3\"->pgl) (1.3.4)\n",
      "Requirement already satisfied: aspy.yaml in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from pre-commit->visualdl>=2.0.0b; python_version >= \"3\"->pgl) (1.3.0)\n",
      "Requirement already satisfied: virtualenv>=15.2 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from pre-commit->visualdl>=2.0.0b; python_version >= \"3\"->pgl) (16.7.9)\n",
      "Requirement already satisfied: setuptools in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from protobuf>=3.11.0->visualdl>=2.0.0b; python_version >= \"3\"->pgl) (41.4.0)\n",
      "Requirement already satisfied: Babel>=2.3 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from Flask-Babel>=1.0.0->visualdl>=2.0.0b; python_version >= \"3\"->pgl) (2.8.0)\n",
      "Requirement already satisfied: pytz in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from Flask-Babel>=1.0.0->visualdl>=2.0.0b; python_version >= \"3\"->pgl) (2019.3)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from requests->visualdl>=2.0.0b; python_version >= \"3\"->pgl) (3.0.4)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from requests->visualdl>=2.0.0b; python_version >= \"3\"->pgl) (2.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from requests->visualdl>=2.0.0b; python_version >= \"3\"->pgl) (2019.9.11)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from requests->visualdl>=2.0.0b; python_version >= \"3\"->pgl) (1.25.6)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from importlib-metadata; python_version < \"3.8\"->flake8>=3.7.9->visualdl>=2.0.0b; python_version >= \"3\"->pgl) (0.6.0)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from Jinja2>=2.10.1->flask>=1.1.1->visualdl>=2.0.0b; python_version >= \"3\"->pgl) (1.1.1)\n",
      "Requirement already satisfied: more-itertools in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from zipp>=0.5->importlib-metadata; python_version < \"3.8\"->flake8>=3.7.9->visualdl>=2.0.0b; python_version >= \"3\"->pgl) (7.2.0)\n",
      "Installing collected packages: redis, redis-py-cluster, pgl\n",
      "Successfully installed pgl-1.2.1 redis-3.5.3 redis-py-cluster-2.1.0\n"
     ]
    }
   ],
   "source": [
    "# !pip install paddlepaddle==1.8.5 # 安装PaddlePaddle\n",
    "!pip install pgl # 安装PGL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 2. 下载PGL代码库"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "docs\t  LICENSE\tpgl\t   README.zh.md      setup.py  tutorials\r\n",
      "examples  ogb_examples\tREADME.md  requirements.txt  tests\r\n"
     ]
    }
   ],
   "source": [
    "# 由于 AIStudio 上访问 github速度比较慢，因此我们提供已经下载好了的 PGL 代码库\n",
    "# !git clone --depth=1 https://github.com/PaddlePaddle/PGL\n",
    "!ls PGL # 查看PGL库根目录"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 3. 运行示例\n",
    "\n",
    "### 3.1 GCN\n",
    "\n",
    "GCN层的具体实现见 PGL/pgl/layers/conv.py\n",
    "\n",
    "NOTE：\n",
    "\n",
    "1. 在GCN模型中，对于图中的某个节点N，相邻节点会将学到的信息发送给它。节点N根据节点的度数给收到的信息加上权重，组合起来作为它新的表示向量。\n",
    "\n",
    "2. GCN模型会在第三节课进行详细介绍。\n",
    "    \n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/sklearn/externals/joblib/externals/cloudpickle/cloudpickle.py:47: DeprecationWarning: the imp module is deprecated in favour of importlib; see the module's documentation for alternative uses\n",
      "  import imp\n",
      "[INFO] 2020-11-24 14:35:23,012 [    train.py:  153]:\tNamespace(dataset='cora', epochs=100, use_cuda=False)\n",
      "/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/numpy/core/fromnumeric.py:3118: RuntimeWarning: Mean of empty slice.\n",
      "  out=out, **kwargs)\n",
      "/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/numpy/core/_methods.py:85: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "[INFO] 2020-11-24 14:35:24,072 [    train.py:  135]:\tEpoch 0 (nan sec) Train Loss: 1.946185 Train Acc: 0.142857 Val Loss: 1.937398 Val Acc: 0.350000 \n",
      "[INFO] 2020-11-24 14:35:24,115 [    train.py:  135]:\tEpoch 1 (nan sec) Train Loss: 1.935671 Train Acc: 0.342857 Val Loss: 1.927820 Val Acc: 0.523333 \n",
      "[INFO] 2020-11-24 14:35:24,170 [    train.py:  135]:\tEpoch 2 (nan sec) Train Loss: 1.924336 Train Acc: 0.471429 Val Loss: 1.918572 Val Acc: 0.413333 \n",
      "[INFO] 2020-11-24 14:35:24,213 [    train.py:  135]:\tEpoch 3 (0.02768 sec) Train Loss: 1.911200 Train Acc: 0.435714 Val Loss: 1.908998 Val Acc: 0.410000 \n",
      "[INFO] 2020-11-24 14:35:24,255 [    train.py:  135]:\tEpoch 4 (0.02735 sec) Train Loss: 1.898517 Train Acc: 0.464286 Val Loss: 1.898026 Val Acc: 0.426667 \n",
      "[INFO] 2020-11-24 14:35:24,298 [    train.py:  135]:\tEpoch 5 (0.02719 sec) Train Loss: 1.883320 Train Acc: 0.478571 Val Loss: 1.886568 Val Acc: 0.453333 \n",
      "[INFO] 2020-11-24 14:35:24,341 [    train.py:  135]:\tEpoch 6 (0.02736 sec) Train Loss: 1.870368 Train Acc: 0.457143 Val Loss: 1.875734 Val Acc: 0.460000 \n",
      "[INFO] 2020-11-24 14:35:24,384 [    train.py:  135]:\tEpoch 7 (0.02734 sec) Train Loss: 1.855206 Train Acc: 0.471429 Val Loss: 1.864528 Val Acc: 0.460000 \n",
      "[INFO] 2020-11-24 14:35:24,429 [    train.py:  135]:\tEpoch 8 (0.02764 sec) Train Loss: 1.839174 Train Acc: 0.478571 Val Loss: 1.853004 Val Acc: 0.450000 \n",
      "[INFO] 2020-11-24 14:35:24,472 [    train.py:  135]:\tEpoch 9 (0.02761 sec) Train Loss: 1.825923 Train Acc: 0.471429 Val Loss: 1.841074 Val Acc: 0.456667 \n",
      "[INFO] 2020-11-24 14:35:24,514 [    train.py:  135]:\tEpoch 10 (0.02751 sec) Train Loss: 1.813848 Train Acc: 0.435714 Val Loss: 1.829241 Val Acc: 0.463333 \n",
      "[INFO] 2020-11-24 14:35:24,558 [    train.py:  135]:\tEpoch 11 (0.02757 sec) Train Loss: 1.795466 Train Acc: 0.421429 Val Loss: 1.817481 Val Acc: 0.460000 \n",
      "[INFO] 2020-11-24 14:35:24,600 [    train.py:  135]:\tEpoch 12 (0.02752 sec) Train Loss: 1.787655 Train Acc: 0.421429 Val Loss: 1.806191 Val Acc: 0.460000 \n",
      "[INFO] 2020-11-24 14:35:24,647 [    train.py:  135]:\tEpoch 13 (0.02789 sec) Train Loss: 1.772201 Train Acc: 0.407143 Val Loss: 1.795176 Val Acc: 0.460000 \n",
      "[INFO] 2020-11-24 14:35:24,690 [    train.py:  135]:\tEpoch 14 (0.02779 sec) Train Loss: 1.758189 Train Acc: 0.471429 Val Loss: 1.784524 Val Acc: 0.460000 \n",
      "[INFO] 2020-11-24 14:35:24,732 [    train.py:  135]:\tEpoch 15 (0.02772 sec) Train Loss: 1.740702 Train Acc: 0.428571 Val Loss: 1.774283 Val Acc: 0.456667 \n",
      "[INFO] 2020-11-24 14:35:24,775 [    train.py:  135]:\tEpoch 16 (0.02770 sec) Train Loss: 1.735026 Train Acc: 0.435714 Val Loss: 1.764541 Val Acc: 0.456667 \n",
      "[INFO] 2020-11-24 14:35:24,817 [    train.py:  135]:\tEpoch 17 (0.02764 sec) Train Loss: 1.703781 Train Acc: 0.464286 Val Loss: 1.754949 Val Acc: 0.463333 \n",
      "[INFO] 2020-11-24 14:35:24,860 [    train.py:  135]:\tEpoch 18 (0.02760 sec) Train Loss: 1.702633 Train Acc: 0.421429 Val Loss: 1.745419 Val Acc: 0.463333 \n",
      "[INFO] 2020-11-24 14:35:24,901 [    train.py:  135]:\tEpoch 19 (0.02754 sec) Train Loss: 1.687885 Train Acc: 0.457143 Val Loss: 1.735724 Val Acc: 0.466667 \n",
      "[INFO] 2020-11-24 14:35:24,945 [    train.py:  135]:\tEpoch 20 (0.02756 sec) Train Loss: 1.679132 Train Acc: 0.428571 Val Loss: 1.726115 Val Acc: 0.470000 \n",
      "[INFO] 2020-11-24 14:35:24,987 [    train.py:  135]:\tEpoch 21 (0.02754 sec) Train Loss: 1.659574 Train Acc: 0.421429 Val Loss: 1.716568 Val Acc: 0.466667 \n",
      "[INFO] 2020-11-24 14:35:25,030 [    train.py:  135]:\tEpoch 22 (0.02753 sec) Train Loss: 1.634195 Train Acc: 0.492857 Val Loss: 1.707134 Val Acc: 0.466667 \n",
      "[INFO] 2020-11-24 14:35:25,074 [    train.py:  135]:\tEpoch 23 (0.02752 sec) Train Loss: 1.630441 Train Acc: 0.471429 Val Loss: 1.697799 Val Acc: 0.466667 \n",
      "[INFO] 2020-11-24 14:35:25,116 [    train.py:  135]:\tEpoch 24 (0.02749 sec) Train Loss: 1.628998 Train Acc: 0.485714 Val Loss: 1.688270 Val Acc: 0.473333 \n",
      "[INFO] 2020-11-24 14:35:25,160 [    train.py:  135]:\tEpoch 25 (0.02754 sec) Train Loss: 1.597275 Train Acc: 0.492857 Val Loss: 1.678585 Val Acc: 0.476667 \n",
      "[INFO] 2020-11-24 14:35:25,203 [    train.py:  135]:\tEpoch 26 (0.02753 sec) Train Loss: 1.594020 Train Acc: 0.478571 Val Loss: 1.668684 Val Acc: 0.476667 \n",
      "[INFO] 2020-11-24 14:35:25,246 [    train.py:  135]:\tEpoch 27 (0.02751 sec) Train Loss: 1.579134 Train Acc: 0.471429 Val Loss: 1.658567 Val Acc: 0.476667 \n",
      "[INFO] 2020-11-24 14:35:25,288 [    train.py:  135]:\tEpoch 28 (0.02748 sec) Train Loss: 1.552680 Train Acc: 0.464286 Val Loss: 1.648050 Val Acc: 0.480000 \n",
      "[INFO] 2020-11-24 14:35:25,335 [    train.py:  135]:\tEpoch 29 (0.02761 sec) Train Loss: 1.559275 Train Acc: 0.500000 Val Loss: 1.637107 Val Acc: 0.486667 \n",
      "[INFO] 2020-11-24 14:35:25,377 [    train.py:  135]:\tEpoch 30 (0.02759 sec) Train Loss: 1.526868 Train Acc: 0.500000 Val Loss: 1.626147 Val Acc: 0.496667 \n",
      "[INFO] 2020-11-24 14:35:25,421 [    train.py:  135]:\tEpoch 31 (0.02761 sec) Train Loss: 1.524132 Train Acc: 0.492857 Val Loss: 1.615052 Val Acc: 0.510000 \n",
      "[INFO] 2020-11-24 14:35:25,465 [    train.py:  135]:\tEpoch 32 (0.02760 sec) Train Loss: 1.482377 Train Acc: 0.528571 Val Loss: 1.603748 Val Acc: 0.516667 \n",
      "[INFO] 2020-11-24 14:35:25,507 [    train.py:  135]:\tEpoch 33 (0.02758 sec) Train Loss: 1.475376 Train Acc: 0.542857 Val Loss: 1.592267 Val Acc: 0.523333 \n",
      "[INFO] 2020-11-24 14:35:25,550 [    train.py:  135]:\tEpoch 34 (0.02758 sec) Train Loss: 1.481455 Train Acc: 0.528571 Val Loss: 1.580759 Val Acc: 0.530000 \n",
      "[INFO] 2020-11-24 14:35:25,593 [    train.py:  135]:\tEpoch 35 (0.02758 sec) Train Loss: 1.471441 Train Acc: 0.485714 Val Loss: 1.569347 Val Acc: 0.530000 \n",
      "[INFO] 2020-11-24 14:35:25,638 [    train.py:  135]:\tEpoch 36 (0.02761 sec) Train Loss: 1.423521 Train Acc: 0.614286 Val Loss: 1.557598 Val Acc: 0.550000 \n",
      "[INFO] 2020-11-24 14:35:25,682 [    train.py:  135]:\tEpoch 37 (0.02763 sec) Train Loss: 1.427988 Train Acc: 0.585714 Val Loss: 1.545247 Val Acc: 0.556667 \n",
      "[INFO] 2020-11-24 14:35:25,726 [    train.py:  135]:\tEpoch 38 (0.02763 sec) Train Loss: 1.361888 Train Acc: 0.642857 Val Loss: 1.532764 Val Acc: 0.566667 \n",
      "[INFO] 2020-11-24 14:35:25,769 [    train.py:  135]:\tEpoch 39 (0.02762 sec) Train Loss: 1.404664 Train Acc: 0.600000 Val Loss: 1.520443 Val Acc: 0.573333 \n",
      "[INFO] 2020-11-24 14:35:25,813 [    train.py:  135]:\tEpoch 40 (0.02763 sec) Train Loss: 1.350403 Train Acc: 0.585714 Val Loss: 1.507765 Val Acc: 0.580000 \n",
      "[INFO] 2020-11-24 14:35:25,857 [    train.py:  135]:\tEpoch 41 (0.02764 sec) Train Loss: 1.386726 Train Acc: 0.585714 Val Loss: 1.495053 Val Acc: 0.596667 \n",
      "[INFO] 2020-11-24 14:35:25,899 [    train.py:  135]:\tEpoch 42 (0.02762 sec) Train Loss: 1.342807 Train Acc: 0.628571 Val Loss: 1.482347 Val Acc: 0.593333 \n",
      "[INFO] 2020-11-24 14:35:25,943 [    train.py:  135]:\tEpoch 43 (0.02764 sec) Train Loss: 1.311738 Train Acc: 0.678571 Val Loss: 1.469172 Val Acc: 0.606667 \n",
      "[INFO] 2020-11-24 14:35:25,991 [    train.py:  135]:\tEpoch 44 (0.02775 sec) Train Loss: 1.324387 Train Acc: 0.642857 Val Loss: 1.455853 Val Acc: 0.610000 \n",
      "[INFO] 2020-11-24 14:35:26,035 [    train.py:  135]:\tEpoch 45 (0.02774 sec) Train Loss: 1.272827 Train Acc: 0.721429 Val Loss: 1.442416 Val Acc: 0.616667 \n",
      "[INFO] 2020-11-24 14:35:26,079 [    train.py:  135]:\tEpoch 46 (0.02774 sec) Train Loss: 1.282629 Train Acc: 0.692857 Val Loss: 1.429290 Val Acc: 0.626667 \n",
      "[INFO] 2020-11-24 14:35:26,125 [    train.py:  135]:\tEpoch 47 (0.02779 sec) Train Loss: 1.240881 Train Acc: 0.692857 Val Loss: 1.416146 Val Acc: 0.636667 \n",
      "[INFO] 2020-11-24 14:35:26,171 [    train.py:  135]:\tEpoch 48 (0.02783 sec) Train Loss: 1.223143 Train Acc: 0.678571 Val Loss: 1.402819 Val Acc: 0.643333 \n",
      "[INFO] 2020-11-24 14:35:26,215 [    train.py:  135]:\tEpoch 49 (0.02784 sec) Train Loss: 1.211636 Train Acc: 0.657143 Val Loss: 1.389506 Val Acc: 0.646667 \n",
      "[INFO] 2020-11-24 14:35:26,258 [    train.py:  135]:\tEpoch 50 (0.02783 sec) Train Loss: 1.195890 Train Acc: 0.721429 Val Loss: 1.376252 Val Acc: 0.646667 \n",
      "[INFO] 2020-11-24 14:35:26,301 [    train.py:  135]:\tEpoch 51 (0.02782 sec) Train Loss: 1.155226 Train Acc: 0.714286 Val Loss: 1.363149 Val Acc: 0.646667 \n",
      "[INFO] 2020-11-24 14:35:26,344 [    train.py:  135]:\tEpoch 52 (0.02782 sec) Train Loss: 1.152210 Train Acc: 0.714286 Val Loss: 1.350167 Val Acc: 0.656667 \n",
      "[INFO] 2020-11-24 14:35:26,387 [    train.py:  135]:\tEpoch 53 (0.02781 sec) Train Loss: 1.166166 Train Acc: 0.728571 Val Loss: 1.337320 Val Acc: 0.660000 \n",
      "[INFO] 2020-11-24 14:35:26,430 [    train.py:  135]:\tEpoch 54 (0.02779 sec) Train Loss: 1.096565 Train Acc: 0.771429 Val Loss: 1.324485 Val Acc: 0.670000 \n",
      "[INFO] 2020-11-24 14:35:26,473 [    train.py:  135]:\tEpoch 55 (0.02778 sec) Train Loss: 1.118437 Train Acc: 0.728571 Val Loss: 1.312128 Val Acc: 0.673333 \n",
      "[INFO] 2020-11-24 14:35:26,516 [    train.py:  135]:\tEpoch 56 (0.02777 sec) Train Loss: 1.086052 Train Acc: 0.757143 Val Loss: 1.299736 Val Acc: 0.676667 \n",
      "[INFO] 2020-11-24 14:35:26,559 [    train.py:  135]:\tEpoch 57 (0.02776 sec) Train Loss: 1.109819 Train Acc: 0.750000 Val Loss: 1.287504 Val Acc: 0.680000 \n",
      "[INFO] 2020-11-24 14:35:26,602 [    train.py:  135]:\tEpoch 58 (0.02776 sec) Train Loss: 1.066681 Train Acc: 0.771429 Val Loss: 1.275070 Val Acc: 0.693333 \n",
      "[INFO] 2020-11-24 14:35:26,648 [    train.py:  135]:\tEpoch 59 (0.02776 sec) Train Loss: 1.030894 Train Acc: 0.757143 Val Loss: 1.262529 Val Acc: 0.703333 \n",
      "[INFO] 2020-11-24 14:35:26,691 [    train.py:  135]:\tEpoch 60 (0.02773 sec) Train Loss: 1.046237 Train Acc: 0.764286 Val Loss: 1.250013 Val Acc: 0.706667 \n",
      "[INFO] 2020-11-24 14:35:26,734 [    train.py:  135]:\tEpoch 61 (0.02773 sec) Train Loss: 1.057186 Train Acc: 0.764286 Val Loss: 1.237465 Val Acc: 0.716667 \n",
      "[INFO] 2020-11-24 14:35:26,777 [    train.py:  135]:\tEpoch 62 (0.02772 sec) Train Loss: 1.027045 Train Acc: 0.728571 Val Loss: 1.225595 Val Acc: 0.720000 \n",
      "[INFO] 2020-11-24 14:35:26,820 [    train.py:  135]:\tEpoch 63 (0.02771 sec) Train Loss: 1.012417 Train Acc: 0.800000 Val Loss: 1.214479 Val Acc: 0.720000 \n",
      "[INFO] 2020-11-24 14:35:26,863 [    train.py:  135]:\tEpoch 64 (0.02771 sec) Train Loss: 0.944846 Train Acc: 0.771429 Val Loss: 1.203937 Val Acc: 0.720000 \n",
      "[INFO] 2020-11-24 14:35:26,906 [    train.py:  135]:\tEpoch 65 (0.02770 sec) Train Loss: 0.972979 Train Acc: 0.771429 Val Loss: 1.193881 Val Acc: 0.730000 \n",
      "[INFO] 2020-11-24 14:35:26,949 [    train.py:  135]:\tEpoch 66 (0.02770 sec) Train Loss: 0.948729 Train Acc: 0.792857 Val Loss: 1.183838 Val Acc: 0.730000 \n",
      "[INFO] 2020-11-24 14:35:26,992 [    train.py:  135]:\tEpoch 67 (0.02769 sec) Train Loss: 0.922943 Train Acc: 0.750000 Val Loss: 1.173660 Val Acc: 0.730000 \n",
      "[INFO] 2020-11-24 14:35:27,035 [    train.py:  135]:\tEpoch 68 (0.02768 sec) Train Loss: 0.958292 Train Acc: 0.778571 Val Loss: 1.163172 Val Acc: 0.736667 \n",
      "[INFO] 2020-11-24 14:35:27,077 [    train.py:  135]:\tEpoch 69 (0.02767 sec) Train Loss: 0.925448 Train Acc: 0.814286 Val Loss: 1.153209 Val Acc: 0.736667 \n",
      "[INFO] 2020-11-24 14:35:27,120 [    train.py:  135]:\tEpoch 70 (0.02767 sec) Train Loss: 0.878701 Train Acc: 0.842857 Val Loss: 1.143276 Val Acc: 0.736667 \n",
      "[INFO] 2020-11-24 14:35:27,164 [    train.py:  135]:\tEpoch 71 (0.02768 sec) Train Loss: 0.905662 Train Acc: 0.814286 Val Loss: 1.133338 Val Acc: 0.740000 \n",
      "[INFO] 2020-11-24 14:35:27,207 [    train.py:  135]:\tEpoch 72 (0.02767 sec) Train Loss: 0.879022 Train Acc: 0.785714 Val Loss: 1.123667 Val Acc: 0.740000 \n",
      "[INFO] 2020-11-24 14:35:27,250 [    train.py:  135]:\tEpoch 73 (0.02766 sec) Train Loss: 0.880817 Train Acc: 0.828571 Val Loss: 1.113799 Val Acc: 0.743333 \n",
      "[INFO] 2020-11-24 14:35:27,293 [    train.py:  135]:\tEpoch 74 (0.02766 sec) Train Loss: 0.871175 Train Acc: 0.835714 Val Loss: 1.104007 Val Acc: 0.746667 \n",
      "[INFO] 2020-11-24 14:35:27,341 [    train.py:  135]:\tEpoch 75 (0.02772 sec) Train Loss: 0.870027 Train Acc: 0.814286 Val Loss: 1.094272 Val Acc: 0.750000 \n",
      "[INFO] 2020-11-24 14:35:27,386 [    train.py:  135]:\tEpoch 76 (0.02773 sec) Train Loss: 0.835869 Train Acc: 0.814286 Val Loss: 1.085243 Val Acc: 0.756667 \n",
      "[INFO] 2020-11-24 14:35:27,430 [    train.py:  135]:\tEpoch 77 (0.02774 sec) Train Loss: 0.883487 Train Acc: 0.800000 Val Loss: 1.076818 Val Acc: 0.763333 \n",
      "[INFO] 2020-11-24 14:35:27,474 [    train.py:  135]:\tEpoch 78 (0.02774 sec) Train Loss: 0.839400 Train Acc: 0.800000 Val Loss: 1.068500 Val Acc: 0.766667 \n",
      "[INFO] 2020-11-24 14:35:27,518 [    train.py:  135]:\tEpoch 79 (0.02774 sec) Train Loss: 0.841634 Train Acc: 0.850000 Val Loss: 1.060051 Val Acc: 0.770000 \n",
      "[INFO] 2020-11-24 14:35:27,561 [    train.py:  135]:\tEpoch 80 (0.02774 sec) Train Loss: 0.812359 Train Acc: 0.821429 Val Loss: 1.052244 Val Acc: 0.776667 \n",
      "[INFO] 2020-11-24 14:35:27,605 [    train.py:  135]:\tEpoch 81 (0.02774 sec) Train Loss: 0.799842 Train Acc: 0.828571 Val Loss: 1.044836 Val Acc: 0.770000 \n",
      "[INFO] 2020-11-24 14:35:27,648 [    train.py:  135]:\tEpoch 82 (0.02774 sec) Train Loss: 0.720036 Train Acc: 0.878571 Val Loss: 1.037211 Val Acc: 0.770000 \n",
      "[INFO] 2020-11-24 14:35:27,692 [    train.py:  135]:\tEpoch 83 (0.02774 sec) Train Loss: 0.737968 Train Acc: 0.864286 Val Loss: 1.030172 Val Acc: 0.766667 \n",
      "[INFO] 2020-11-24 14:35:27,735 [    train.py:  135]:\tEpoch 84 (0.02774 sec) Train Loss: 0.763071 Train Acc: 0.878571 Val Loss: 1.023598 Val Acc: 0.770000 \n",
      "[INFO] 2020-11-24 14:35:27,778 [    train.py:  135]:\tEpoch 85 (0.02774 sec) Train Loss: 0.775600 Train Acc: 0.857143 Val Loss: 1.017404 Val Acc: 0.773333 \n",
      "[INFO] 2020-11-24 14:35:27,821 [    train.py:  135]:\tEpoch 86 (0.02773 sec) Train Loss: 0.754057 Train Acc: 0.892857 Val Loss: 1.011005 Val Acc: 0.776667 \n",
      "[INFO] 2020-11-24 14:35:27,864 [    train.py:  135]:\tEpoch 87 (0.02772 sec) Train Loss: 0.756406 Train Acc: 0.878571 Val Loss: 1.004001 Val Acc: 0.783333 \n",
      "[INFO] 2020-11-24 14:35:27,907 [    train.py:  135]:\tEpoch 88 (0.02772 sec) Train Loss: 0.743661 Train Acc: 0.885714 Val Loss: 0.996710 Val Acc: 0.783333 \n",
      "[INFO] 2020-11-24 14:35:27,950 [    train.py:  135]:\tEpoch 89 (0.02772 sec) Train Loss: 0.755894 Train Acc: 0.864286 Val Loss: 0.989898 Val Acc: 0.783333 \n",
      "[INFO] 2020-11-24 14:35:27,999 [    train.py:  135]:\tEpoch 90 (0.02772 sec) Train Loss: 0.728832 Train Acc: 0.864286 Val Loss: 0.983047 Val Acc: 0.786667 \n",
      "[INFO] 2020-11-24 14:35:28,043 [    train.py:  135]:\tEpoch 91 (0.02773 sec) Train Loss: 0.696529 Train Acc: 0.900000 Val Loss: 0.976196 Val Acc: 0.793333 \n",
      "[INFO] 2020-11-24 14:35:28,086 [    train.py:  135]:\tEpoch 92 (0.02773 sec) Train Loss: 0.741594 Train Acc: 0.871429 Val Loss: 0.969892 Val Acc: 0.793333 \n",
      "[INFO] 2020-11-24 14:35:28,130 [    train.py:  135]:\tEpoch 93 (0.02773 sec) Train Loss: 0.681129 Train Acc: 0.871429 Val Loss: 0.963948 Val Acc: 0.793333 \n",
      "[INFO] 2020-11-24 14:35:28,173 [    train.py:  135]:\tEpoch 94 (0.02773 sec) Train Loss: 0.670672 Train Acc: 0.892857 Val Loss: 0.958294 Val Acc: 0.793333 \n",
      "[INFO] 2020-11-24 14:35:28,216 [    train.py:  135]:\tEpoch 95 (0.02772 sec) Train Loss: 0.700566 Train Acc: 0.871429 Val Loss: 0.952930 Val Acc: 0.793333 \n",
      "[INFO] 2020-11-24 14:35:28,259 [    train.py:  135]:\tEpoch 96 (0.02771 sec) Train Loss: 0.687270 Train Acc: 0.871429 Val Loss: 0.948623 Val Acc: 0.796667 \n",
      "[INFO] 2020-11-24 14:35:28,302 [    train.py:  135]:\tEpoch 97 (0.02771 sec) Train Loss: 0.637869 Train Acc: 0.878571 Val Loss: 0.944386 Val Acc: 0.793333 \n",
      "[INFO] 2020-11-24 14:35:28,347 [    train.py:  135]:\tEpoch 98 (0.02772 sec) Train Loss: 0.679080 Train Acc: 0.900000 Val Loss: 0.939481 Val Acc: 0.793333 \n",
      "[INFO] 2020-11-24 14:35:28,392 [    train.py:  135]:\tEpoch 99 (0.02773 sec) Train Loss: 0.696660 Train Acc: 0.864286 Val Loss: 0.935254 Val Acc: 0.793333 \n",
      "[INFO] 2020-11-24 14:35:28,408 [    train.py:  143]:\tAccuracy: 0.759000\n"
     ]
    }
   ],
   "source": [
    "!cd PGL/examples/gcn; python train.py --epochs 100 # 切换到gcn的目录，运行train.py在cora数据集上训练  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "<br>\n",
    "\n",
    "### 3.2 DeepWalk\n",
    "\n",
    "模型代码详见 PGL/examples/deepwalk/deepwalk.py\n",
    "\n",
    "NOTE: \n",
    "\n",
    "1. DeepWalk的主要原理是通过随机游走生成节点路径，然后将其作为词向量模型SkipGram的输入来学习节点表示。\n",
    "\n",
    "2. DeepWalk 模型会在第二节课详细介绍。\n",
    "    \n",
    "<br>\n",
    "\n",
    "**Step1 学习节点表示**\n",
    "\n",
    "查看deepwalk.py中的parser(239行起)，修改不同参数的值，观察其对训练结果的影响，比如游走路径长度walk_len，SkipGram窗口大小win_size等\n",
    "\n",
    "**Tips** \n",
    "\n",
    "1. 如果出现内存不足的问题，可以调小batch_size参数\n",
    "2. 以下设置的参数为了让同学们可以快速跑出结果，设置的 epoch、walk_len、hidden_size 均比较小，可以自行尝试调大这些值。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/sklearn/externals/joblib/externals/cloudpickle/cloudpickle.py:47: DeprecationWarning: the imp module is deprecated in favour of importlib; see the module's documentation for alternative uses\n",
      "  import imp\n",
      "[INFO] 2020-11-24 14:36:01,632 [ deepwalk.py:  258]:\tNamespace(batch_size=256, dataset='ArXiv', epoch=2, hidden_size=10, neg_num=20, offline_learning=True, processes=1, save_path='./tmp/deepwalk_ArXiv', use_cuda=False, walk_len=10, win_size=10)\n",
      "[INFO] 2020-11-24 14:36:02,430 [ deepwalk.py:  172]:\tStart random walk on disk...\n",
      "[INFO] 2020-11-24 14:36:03,184 [ deepwalk.py:  182]:\tRandom walk on disk Done.\n",
      "2020-11-24 14:36:03,185-WARNING: paddle.fluid.layers.py_reader() may be deprecated in the near future. Please use paddle.fluid.io.DataLoader.from_generator() instead.\n",
      "[INFO] 2020-11-24 14:36:03,601 [ deepwalk.py:  228]:\tStep 0 Deepwalk Loss: 0.724576  0.372420 s/step.\n",
      "[INFO] 2020-11-24 14:36:14,487 [ deepwalk.py:  228]:\tStep 50 Deepwalk Loss: 0.644198  0.215872 s/step.\n",
      "[INFO] 2020-11-24 14:36:21,202 [ deepwalk.py:  228]:\tStep 100 Deepwalk Loss: 0.568986  0.075070 s/step.\n",
      "[INFO] 2020-11-24 14:36:25,024 [ deepwalk.py:  228]:\tStep 150 Deepwalk Loss: 0.546118  0.074450 s/step.\n",
      "[INFO] 2020-11-24 14:36:28,813 [ deepwalk.py:  228]:\tStep 200 Deepwalk Loss: 0.547902  0.076921 s/step.\n",
      "[INFO] 2020-11-24 14:36:32,637 [ deepwalk.py:  228]:\tStep 250 Deepwalk Loss: 0.545251  0.075461 s/step.\n",
      "[INFO] 2020-11-24 14:36:36,471 [ deepwalk.py:  228]:\tStep 300 Deepwalk Loss: 0.544639  0.077662 s/step.\n",
      "[INFO] 2020-11-24 14:36:40,274 [ deepwalk.py:  228]:\tStep 350 Deepwalk Loss: 0.536977  0.074419 s/step.\n",
      "[INFO] 2020-11-24 14:36:48,757 [ deepwalk.py:  228]:\tStep 400 Deepwalk Loss: 0.529961  0.213211 s/step.\n",
      "[INFO] 2020-11-24 14:36:58,960 [ deepwalk.py:  228]:\tStep 450 Deepwalk Loss: 0.524064  0.207546 s/step.\n",
      "[INFO] 2020-11-24 14:37:09,422 [ deepwalk.py:  228]:\tStep 500 Deepwalk Loss: 0.527823  0.211965 s/step.\n",
      "[INFO] 2020-11-24 14:37:19,968 [ deepwalk.py:  228]:\tStep 550 Deepwalk Loss: 0.525310  0.214373 s/step.\n",
      "[INFO] 2020-11-24 14:37:28,677 [ deepwalk.py:  228]:\tStep 600 Deepwalk Loss: 0.539174  0.078960 s/step.\n",
      "[INFO] 2020-11-24 14:37:32,627 [ deepwalk.py:  228]:\tStep 650 Deepwalk Loss: 0.540447  0.077189 s/step.\n",
      "[INFO] 2020-11-24 14:37:42,022 [ deepwalk.py:  228]:\tStep 700 Deepwalk Loss: 0.537241  0.211411 s/step.\n",
      "[INFO] 2020-11-24 14:37:50,225 [ deepwalk.py:  228]:\tStep 750 Deepwalk Loss: 0.541432  0.079251 s/step.\n",
      "[INFO] 2020-11-24 14:37:54,213 [ deepwalk.py:  228]:\tStep 800 Deepwalk Loss: 0.540765  0.077490 s/step.\n",
      "[INFO] 2020-11-24 14:37:58,127 [ deepwalk.py:  228]:\tStep 850 Deepwalk Loss: 0.539415  0.080149 s/step.\n",
      "[INFO] 2020-11-24 14:38:02,101 [ deepwalk.py:  228]:\tStep 900 Deepwalk Loss: 0.532488  0.079324 s/step.\n",
      "[INFO] 2020-11-24 14:38:05,991 [ deepwalk.py:  228]:\tStep 950 Deepwalk Loss: 0.534465  0.077003 s/step.\n",
      "[INFO] 2020-11-24 14:38:16,322 [ deepwalk.py:  228]:\tStep 1000 Deepwalk Loss: 0.534607  0.216003 s/step.\n",
      "[INFO] 2020-11-24 14:38:23,716 [ deepwalk.py:  228]:\tStep 1050 Deepwalk Loss: 0.541579  0.076334 s/step.\n",
      "[INFO] 2020-11-24 14:38:27,767 [ deepwalk.py:  228]:\tStep 1100 Deepwalk Loss: 0.530346  0.215230 s/step.\n",
      "[INFO] 2020-11-24 14:38:38,293 [ deepwalk.py:  228]:\tStep 1150 Deepwalk Loss: 0.523066  0.215668 s/step.\n",
      "[INFO] 2020-11-24 14:38:48,817 [ deepwalk.py:  228]:\tStep 1200 Deepwalk Loss: 0.524576  0.206781 s/step.\n",
      "[INFO] 2020-11-24 14:38:59,457 [ deepwalk.py:  228]:\tStep 1250 Deepwalk Loss: 0.531868  0.214398 s/step.\n",
      "[INFO] 2020-11-24 14:39:09,990 [ deepwalk.py:  228]:\tStep 1300 Deepwalk Loss: 0.523190  0.209884 s/step.\n",
      "[INFO] 2020-11-24 14:39:20,550 [ deepwalk.py:  228]:\tStep 1350 Deepwalk Loss: 0.532175  0.212429 s/step.\n",
      "[INFO] 2020-11-24 14:39:30,194 [ deepwalk.py:  228]:\tStep 1400 Deepwalk Loss: 0.534883  0.085832 s/step.\n",
      "[INFO] 2020-11-24 14:39:34,124 [ deepwalk.py:  228]:\tStep 1450 Deepwalk Loss: 0.538972  0.078368 s/step.\n"
     ]
    }
   ],
   "source": [
    "!cd PGL/examples/deepwalk/; python deepwalk.py --dataset ArXiv --save_path ./tmp/deepwalk_ArXiv --offline_learning --epoch 2 --batch_size 256 --processes 1 --walk_len 10 --hidden_size 10 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "<br>\n",
    "\n",
    "**Step2 链接预测任务上的测试**\n",
    "\n",
    "这里选用的数据集是ArXiv，它包含了天体物理学类的论文作者间的合作关系图，得到的节点表示存储在 ./tmp/deepwalk_Arxiv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/sklearn/externals/joblib/externals/cloudpickle/cloudpickle.py:47: DeprecationWarning: the imp module is deprecated in favour of importlib; see the module's documentation for alternative uses\n",
      "  import imp\n",
      "[INFO] 2020-11-24 14:40:44,192 [link_predict.py:  233]:\tNamespace(batch_size=None, ckpt_path='./tmp/deepwalk_Arxiv/paddle_model', dataset='ArXiv', epoch=50, hidden_size=128, use_cuda=False)\n",
      "2020-11-24 14:40:44,980-WARNING: paddle.fluid.layers.py_reader() may be deprecated in the near future. Please use paddle.fluid.io.DataLoader.from_generator() instead.\n",
      "2020-11-24 14:40:44,999-WARNING: paddle.fluid.layers.py_reader() may be deprecated in the near future. Please use paddle.fluid.io.DataLoader.from_generator() instead.\n",
      "/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/executor.py:1093: UserWarning: There are no operators in the program to be executed. If you pass Program manually, please use fluid.program_guard to ensure the current Program is being used.\n",
      "  warnings.warn(error_info)\n",
      "[INFO] 2020-11-24 14:40:45,836 [link_predict.py:  215]:\t\tStep 1 Test Loss: 0.693220 Test AUC: 0.503291 \n",
      "[INFO] 2020-11-24 14:40:46,125 [link_predict.py:  215]:\t\tStep 2 Test Loss: 0.693154 Test AUC: 0.504987 \n",
      "[INFO] 2020-11-24 14:40:46,407 [link_predict.py:  215]:\t\tStep 3 Test Loss: 0.693156 Test AUC: 0.506682 \n",
      "[INFO] 2020-11-24 14:40:46,692 [link_predict.py:  215]:\t\tStep 4 Test Loss: 0.693183 Test AUC: 0.508276 \n",
      "[INFO] 2020-11-24 14:40:46,979 [link_predict.py:  215]:\t\tStep 5 Test Loss: 0.693178 Test AUC: 0.509675 \n",
      "[INFO] 2020-11-24 14:40:47,265 [link_predict.py:  215]:\t\tStep 6 Test Loss: 0.693150 Test AUC: 0.510915 \n",
      "[INFO] 2020-11-24 14:40:47,546 [link_predict.py:  215]:\t\tStep 7 Test Loss: 0.693138 Test AUC: 0.512049 \n",
      "[INFO] 2020-11-24 14:40:47,831 [link_predict.py:  215]:\t\tStep 8 Test Loss: 0.693144 Test AUC: 0.513095 \n",
      "[INFO] 2020-11-24 14:40:48,122 [link_predict.py:  215]:\t\tStep 9 Test Loss: 0.693156 Test AUC: 0.514046 \n",
      "[INFO] 2020-11-24 14:40:48,290 [link_predict.py:  192]:\tStep 10 Train Loss: 0.693155 Train AUC: 0.518355 \n",
      "[INFO] 2020-11-24 14:40:48,418 [link_predict.py:  215]:\t\tStep 10 Test Loss: 0.693159 Test AUC: 0.514895 \n",
      "[INFO] 2020-11-24 14:40:48,710 [link_predict.py:  215]:\t\tStep 11 Test Loss: 0.693156 Test AUC: 0.515638 \n",
      "[INFO] 2020-11-24 14:40:49,004 [link_predict.py:  215]:\t\tStep 12 Test Loss: 0.693147 Test AUC: 0.516283 \n",
      "[INFO] 2020-11-24 14:40:49,357 [link_predict.py:  215]:\t\tStep 13 Test Loss: 0.693137 Test AUC: 0.516842 \n",
      "[INFO] 2020-11-24 14:40:49,651 [link_predict.py:  215]:\t\tStep 14 Test Loss: 0.693139 Test AUC: 0.517322 \n",
      "[INFO] 2020-11-24 14:40:49,945 [link_predict.py:  215]:\t\tStep 15 Test Loss: 0.693141 Test AUC: 0.517741 \n",
      "[INFO] 2020-11-24 14:40:50,238 [link_predict.py:  215]:\t\tStep 16 Test Loss: 0.693148 Test AUC: 0.518102 \n",
      "[INFO] 2020-11-24 14:40:50,535 [link_predict.py:  215]:\t\tStep 17 Test Loss: 0.693147 Test AUC: 0.518418 \n",
      "[INFO] 2020-11-24 14:40:50,830 [link_predict.py:  215]:\t\tStep 18 Test Loss: 0.693143 Test AUC: 0.518698 \n",
      "[INFO] 2020-11-24 14:40:51,124 [link_predict.py:  215]:\t\tStep 19 Test Loss: 0.693138 Test AUC: 0.518942 \n",
      "[INFO] 2020-11-24 14:40:51,289 [link_predict.py:  192]:\tStep 20 Train Loss: 0.693135 Train AUC: 0.525268 \n",
      "[INFO] 2020-11-24 14:40:51,415 [link_predict.py:  215]:\t\tStep 20 Test Loss: 0.693135 Test AUC: 0.519153 \n",
      "[INFO] 2020-11-24 14:40:51,706 [link_predict.py:  215]:\t\tStep 21 Test Loss: 0.693137 Test AUC: 0.519336 \n",
      "[INFO] 2020-11-24 14:40:51,998 [link_predict.py:  215]:\t\tStep 22 Test Loss: 0.693137 Test AUC: 0.519498 \n",
      "[INFO] 2020-11-24 14:40:52,289 [link_predict.py:  215]:\t\tStep 23 Test Loss: 0.693137 Test AUC: 0.519640 \n",
      "[INFO] 2020-11-24 14:40:52,581 [link_predict.py:  215]:\t\tStep 24 Test Loss: 0.693137 Test AUC: 0.519764 \n",
      "[INFO] 2020-11-24 14:40:52,871 [link_predict.py:  215]:\t\tStep 25 Test Loss: 0.693136 Test AUC: 0.519876 \n",
      "[INFO] 2020-11-24 14:40:53,161 [link_predict.py:  215]:\t\tStep 26 Test Loss: 0.693134 Test AUC: 0.519972 \n",
      "[INFO] 2020-11-24 14:40:53,455 [link_predict.py:  215]:\t\tStep 27 Test Loss: 0.693133 Test AUC: 0.520059 \n",
      "[INFO] 2020-11-24 14:40:53,741 [link_predict.py:  215]:\t\tStep 28 Test Loss: 0.693133 Test AUC: 0.520135 \n",
      "[INFO] 2020-11-24 14:40:54,026 [link_predict.py:  215]:\t\tStep 29 Test Loss: 0.693132 Test AUC: 0.520203 \n",
      "[INFO] 2020-11-24 14:40:54,187 [link_predict.py:  192]:\tStep 30 Train Loss: 0.693127 Train AUC: 0.527323 \n",
      "[INFO] 2020-11-24 14:40:54,312 [link_predict.py:  215]:\t\tStep 30 Test Loss: 0.693133 Test AUC: 0.520262 \n",
      "[INFO] 2020-11-24 14:40:54,596 [link_predict.py:  215]:\t\tStep 31 Test Loss: 0.693133 Test AUC: 0.520315 \n",
      "[INFO] 2020-11-24 14:40:54,882 [link_predict.py:  215]:\t\tStep 32 Test Loss: 0.693133 Test AUC: 0.520361 \n",
      "[INFO] 2020-11-24 14:40:55,164 [link_predict.py:  215]:\t\tStep 33 Test Loss: 0.693133 Test AUC: 0.520402 \n",
      "[INFO] 2020-11-24 14:40:55,449 [link_predict.py:  215]:\t\tStep 34 Test Loss: 0.693131 Test AUC: 0.520441 \n",
      "[INFO] 2020-11-24 14:40:55,733 [link_predict.py:  215]:\t\tStep 35 Test Loss: 0.693130 Test AUC: 0.520473 \n",
      "[INFO] 2020-11-24 14:40:56,015 [link_predict.py:  215]:\t\tStep 36 Test Loss: 0.693130 Test AUC: 0.520503 \n",
      "[INFO] 2020-11-24 14:40:56,299 [link_predict.py:  215]:\t\tStep 37 Test Loss: 0.693130 Test AUC: 0.520528 \n",
      "[INFO] 2020-11-24 14:40:56,579 [link_predict.py:  215]:\t\tStep 38 Test Loss: 0.693129 Test AUC: 0.520549 \n",
      "[INFO] 2020-11-24 14:40:56,865 [link_predict.py:  215]:\t\tStep 39 Test Loss: 0.693130 Test AUC: 0.520569 \n",
      "[INFO] 2020-11-24 14:40:57,025 [link_predict.py:  192]:\tStep 40 Train Loss: 0.693122 Train AUC: 0.528016 \n",
      "[INFO] 2020-11-24 14:40:57,149 [link_predict.py:  215]:\t\tStep 40 Test Loss: 0.693129 Test AUC: 0.520585 \n",
      "[INFO] 2020-11-24 14:40:57,433 [link_predict.py:  215]:\t\tStep 41 Test Loss: 0.693129 Test AUC: 0.520598 \n",
      "[INFO] 2020-11-24 14:40:57,714 [link_predict.py:  215]:\t\tStep 42 Test Loss: 0.693129 Test AUC: 0.520611 \n",
      "[INFO] 2020-11-24 14:40:57,999 [link_predict.py:  215]:\t\tStep 43 Test Loss: 0.693130 Test AUC: 0.520623 \n",
      "[INFO] 2020-11-24 14:40:58,288 [link_predict.py:  215]:\t\tStep 44 Test Loss: 0.693129 Test AUC: 0.520633 \n",
      "[INFO] 2020-11-24 14:40:58,581 [link_predict.py:  215]:\t\tStep 45 Test Loss: 0.693128 Test AUC: 0.520641 \n",
      "[INFO] 2020-11-24 14:40:58,869 [link_predict.py:  215]:\t\tStep 46 Test Loss: 0.693128 Test AUC: 0.520647 \n",
      "[INFO] 2020-11-24 14:40:59,152 [link_predict.py:  215]:\t\tStep 47 Test Loss: 0.693129 Test AUC: 0.520652 \n",
      "[INFO] 2020-11-24 14:40:59,434 [link_predict.py:  215]:\t\tStep 48 Test Loss: 0.693129 Test AUC: 0.520656 \n",
      "[INFO] 2020-11-24 14:40:59,717 [link_predict.py:  215]:\t\tStep 49 Test Loss: 0.693128 Test AUC: 0.520659 \n",
      "[INFO] 2020-11-24 14:40:59,882 [link_predict.py:  192]:\tStep 50 Train Loss: 0.693121 Train AUC: 0.528213 \n",
      "[INFO] 2020-11-24 14:41:00,010 [link_predict.py:  215]:\t\tStep 50 Test Loss: 0.693128 Test AUC: 0.520660 \n"
     ]
    }
   ],
   "source": [
    "!cd ./PGL/examples/deepwalk/; python link_predict.py --ckpt_path ./tmp/deepwalk_Arxiv/paddle_model --epoch 50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 4.本地作业\n",
    "**本地作业：飞桨本地测试代码运行成功截图和GCN例子运行成功截图**\n",
    "\n",
    "**####请在下面cell中上传飞桨安装成功的截图和GCN例子运行成功截图####**\n",
    "\n",
    "### 4.1 飞桨相关信息(上传paddle.fluid.install_check.run_check()之后的截图)：\n",
    "\n",
    "飞桨安装文档：[https://paddlepaddle.org.cn/install/quick](https://paddlepaddle.org.cn/install/quick)\n",
    "\n",
    "提示：使用 python 进入python解释器，输入import paddle.fluid ，再输入 paddle.fluid.install_check.run_check()。\n",
    "如果出现 Your Paddle Fluid is installed successfully!，说明您已成功安装。\n",
    "\n",
    "本地安装PaddlePaddle的常见错误：[https://aistudio.baidu.com/aistudio/projectdetail/697227](https://aistudio.baidu.com/aistudio/projectdetail/697227)\n",
    "\n",
    "手把手教你 win10 安装Paddlepaddle-GPU：[https://aistudio.baidu.com/aistudio/projectdetail/696822](https://aistudio.baidu.com/aistudio/projectdetail/696822)\n",
    "\n",
    "### 4.2 PGL相关信息(上传运行示例-GCN的截图)：\n",
    "\n",
    "    pip install pgl # 安装PGL\n",
    "\n",
    "    git clone --depth=1 https://github.com/PaddlePaddle/PGL #下载PGL代码库(或者直接把左边文件中的下载到本地)\n",
    "\t\t\n",
    "    # 运行示例-GCN\n",
    "    cd PGL/examples/gcn; python train.py --epochs 100 # 切换到gcn的目录，运行train.py在cora数据集上训练  \n",
    "    \n",
    "\n",
    "\t\t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "![](https://ai-studio-static-online.cdn.bcebos.com/f5d157d35ae2429d8f62d3bbb8949dc0b2a941d31ff04e26a79db1d0b121ea8e)\n",
    "![](https://ai-studio-static-online.cdn.bcebos.com/824e77d482e14fa19b2360876a3d9341f391f0dace16475d99e20d6123bc07d1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 5. 代码框架梳理（可选）\n",
    "\n",
    "本小节以GCN的 PGL/examples/gcn/train.py 为例，简单介绍一下图模型的训练框架。\n",
    "\n",
    "### 5.1 参数设置\n",
    "\n",
    "可修改parser的参数来使用不同的数据集进行训练\n",
    "\n",
    "```python\n",
    "if __name__ == '__main__':\n",
    "    parser = argparse.ArgumentParser(description='GCN')\n",
    "    # 设置数据集，默认选择cora数据集\n",
    "    parser.add_argument(\n",
    "        \"--dataset\", type=str, default=\"cora\", help=\"dataset (cora, pubmed)\")\n",
    "    # 设置是否使用GPU\n",
    "    parser.add_argument(\"--use_cuda\", action='store_true', help=\"use_cuda\")\n",
    "    args = parser.parse_args()\n",
    "    log.info(args)\n",
    "    main(args)\n",
    "```\n",
    "\n",
    "\n",
    "### 5.2 数据预处理\n",
    "\n",
    "读取数据后，需要进行一些预处理，例如GCN中对图中节点度数进行了标准化\n",
    "\n",
    "```python\n",
    "dataset = load(args.dataset)\n",
    "\n",
    "indegree = dataset.graph.indegree()\n",
    "norm = np.zeros_like(indegree, dtype=\"float32\")\n",
    "norm[indegree > 0] = np.power(indegree[indegree > 0], -0.5)\n",
    "dataset.graph.node_feat[\"norm\"] = np.expand_dims(norm, -1)\n",
    "```\n",
    "\n",
    "\n",
    "### 5.3 模型构建\n",
    "\n",
    "\n",
    "**Step1 实例化[GraphWrapper](https://github.com/PaddlePaddle/PGL/blob/main/pgl/graph_wrapper.py)和[Program](https://www.paddlepaddle.org.cn/documentation/docs/zh/beginners_guide/basic_concept/program.html)**\n",
    "\n",
    "- 定义train_program、startup_program和test_program等程序\n",
    "\n",
    "```python\n",
    "  place = fluid.CUDAPlace(0) if args.use_cuda else fluid.CPUPlace()\n",
    "  train_program = fluid.Program()\n",
    "  startup_program = fluid.Program()\n",
    "  test_program = fluid.Program()\n",
    "```\n",
    "\n",
    "- 实例化GraphWrapper，它提供了图的基本信息，以及GNN算法message passing机制中的send和receive两个接口。\n",
    "\n",
    "```python\n",
    "with fluid.program_guard(train_program, startup_program): \n",
    "    gw = pgl.graph_wrapper.GraphWrapper(\n",
    "        name=\"graph\",\n",
    "        place=place,\n",
    "        node_feat=dataset.graph.node_feat_info())\n",
    "```\n",
    "\n",
    "**Step2 模型定义**\n",
    "\n",
    "在train_program中定义要使用的模型结构，这里是双层的GCN模型\n",
    "\n",
    "```python\n",
    "    output = pgl.layers.gcn(gw,\n",
    "                            gw.node_feat[\"words\"],\n",
    "                            hidden_size,\n",
    "                            activation=\"relu\",\n",
    "                            norm=gw.node_feat['norm'],\n",
    "                            name=\"gcn_layer_1\")\n",
    "    output = fluid.layers.dropout(\n",
    "        output, 0.5, dropout_implementation='upscale_in_train')\n",
    "    output = pgl.layers.gcn(gw,\n",
    "                            output,\n",
    "                            dataset.num_classes,\n",
    "                            activation=None,\n",
    "                            norm=gw.node_feat['norm'],\n",
    "                            name=\"gcn_layer_2\")\n",
    "```\n",
    "\n",
    "**Step3 损失函数计算**\n",
    "\n",
    "- node_index和node_label定义了有标签样本的数据下标和标签数据\n",
    "\n",
    "```python\n",
    "    node_index = fluid.layers.data(\n",
    "        \"node_index\",\n",
    "        shape=[None, 1],\n",
    "        dtype=\"int64\",\n",
    "        append_batch_size=False)\n",
    "    node_label = fluid.layers.data(\n",
    "        \"node_label\",\n",
    "        shape=[None, 1],\n",
    "        dtype=\"int64\",\n",
    "        append_batch_size=False)\n",
    "```        \n",
    "\n",
    "- 使用gather函数找出output中有标签样本的预测结果后，计算得到交叉熵损失函数值以及准确度\n",
    "\n",
    "```python\n",
    "    pred = fluid.layers.gather(output, node_index)\n",
    "    loss, pred = fluid.layers.softmax_with_cross_entropy(\n",
    "        logits=pred, label=node_label, return_softmax=True)\n",
    "    acc = fluid.layers.accuracy(input=pred, label=node_label, k=1)\n",
    "    loss = fluid.layers.mean(loss)\n",
    "```\n",
    "\n",
    "**Step4 构造测试程序**\n",
    "\n",
    "复制构造test_program的静态图。到此为止，train_program和test_program的静态图结构完全相同，区别在于test_program不需要梯度计算和反向传播过程。\n",
    "\n",
    "```python\n",
    "test_program = train_program.clone(for_test=True)\n",
    "```\n",
    "\n",
    "**Step5 定义优化器**\n",
    "\n",
    "为了实现train_program上的参数更新，需要定义优化器和优化目标，这里是用Adam最小化loss\n",
    "\n",
    "```python\n",
    "with fluid.program_guard(train_program, startup_program):\n",
    "    adam = fluid.optimizer.Adam(\n",
    "        learning_rate=1e-2,\n",
    "        regularization=fluid.regularizer.L2DecayRegularizer(\n",
    "            regularization_coeff=0.0005))\n",
    "    adam.minimize(loss)\n",
    "```\n",
    "\n",
    "\n",
    "### 5.4 模型训练和测试\n",
    "\n",
    "模型构建完成后，就可以定义一个Executor来执行program了\n",
    "\n",
    "```python\n",
    "exe = fluid.Executor(place)\n",
    "```\n",
    "\n",
    "**Step1 初始化**\n",
    "\n",
    "执行startup_program进行初始化\n",
    "\n",
    "```python\n",
    "exe.run(startup_program)\n",
    "```\n",
    "\n",
    "**Step2 数据准备**\n",
    "\n",
    "将预处理阶段读取到的数据集填充到GraphWrapper中，同时准备好训练、验证和测试阶段用到的样本下标和标签数据\n",
    "\n",
    "```python\n",
    "feed_dict = gw.to_feed(dataset.graph)\n",
    "\n",
    "train_index = dataset.train_index\n",
    "train_label = np.expand_dims(dataset.y[train_index], -1)\n",
    "train_index = np.expand_dims(train_index, -1)\n",
    "\n",
    "val_index = dataset.val_index\n",
    "val_label = np.expand_dims(dataset.y[val_index], -1)\n",
    "val_index = np.expand_dims(val_index, -1)\n",
    "\n",
    "test_index = dataset.test_index\n",
    "test_label = np.expand_dims(dataset.y[test_index], -1)\n",
    "test_index = np.expand_dims(test_index, -1)\n",
    "```\n",
    "\n",
    "**Step3 训练和测试**\n",
    "\n",
    "给Executor分别传入不同的program来执行训练和测试过程\n",
    "\n",
    "- feed以字典形式给定了输入数据 {变量名：numpy数据}\n",
    "- fetch_list给定了模型中需要取出结果的变量名，可以根据需要自行修改\n",
    "\n",
    "```python\n",
    "dur = []\n",
    "for epoch in range(200):\n",
    "    if epoch >= 3:\n",
    "        t0 = time.time()\n",
    "    feed_dict[\"node_index\"] = np.array(train_index, dtype=\"int64\")\n",
    "    feed_dict[\"node_label\"] = np.array(train_label, dtype=\"int64\")\n",
    "    train_loss, train_acc = exe.run(train_program,\n",
    "                                        feed=feed_dict,\n",
    "                                        fetch_list=[loss, acc],\n",
    "                                        return_numpy=True)\n",
    "\n",
    "\t# 3个epoch后，统计每轮训练执行的时间然后求均值。\n",
    "    if epoch >= 3:\n",
    "        time_per_epoch = 1.0 * (time.time() - t0)\n",
    "        dur.append(time_per_epoch)\n",
    "    feed_dict[\"node_index\"] = np.array(val_index, dtype=\"int64\")\n",
    "    feed_dict[\"node_label\"] = np.array(val_label, dtype=\"int64\")\n",
    "    val_loss, val_acc = exe.run(test_program,\n",
    "                                    feed=feed_dict,\n",
    "                                    fetch_list=[loss, acc],\n",
    "                                    return_numpy=True)\n",
    "\n",
    "    log.info(\"Epoch %d \" % epoch + \"(%.5lf sec) \" % np.mean(dur) +\n",
    "                 \"Train Loss: %f \" % train_loss + \"Train Acc: %f \" % train_acc\n",
    "                 + \"Val Loss: %f \" % val_loss + \"Val Acc: %f \" % val_acc)\n",
    "\n",
    "feed_dict[\"node_index\"] = np.array(test_index, dtype=\"int64\")\n",
    "feed_dict[\"node_label\"] = np.array(test_label, dtype=\"int64\")\n",
    "test_loss, test_acc = exe.run(test_program,\n",
    "                                  feed=feed_dict,\n",
    "                                  fetch_list=[loss, acc],\n",
    "                                  return_numpy=True)\n",
    "log.info(\"Accuracy: %f\" % test_acc)\n",
    "```\n",
    "\n",
    "图模型训练的基本框架大概就是这样啦，下次再见咯~"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PaddlePaddle 1.8.4 (Python 3.5)",
   "language": "python",
   "name": "py35-paddle1.2.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
